{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80517dbc",
   "metadata": {
    "id": "80517dbc"
   },
   "source": [
    "# GRPO Training project: teach an LLM to do additions, again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DAEbh3jBadc7",
   "metadata": {
    "id": "DAEbh3jBadc7"
   },
   "source": [
    "In this notebook, you'll find:\n",
    "* A basic Transformer with basic tokenizer\n",
    "* A basic dataset for additions\n",
    "* A classical pre-trainer, minimizing cross entropy loss\n",
    "* A Vanilla GRPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MB8lj855LgHl",
   "metadata": {
    "id": "MB8lj855LgHl"
   },
   "source": [
    "You're not supposed to edit the existing code (you can if you want to...).\n",
    "You should implement one (or more) of the following:\n",
    "* GRPO with PPO (the `usual` one)\n",
    "* RLOO\n",
    "* ReMax\n",
    "* DPO\n",
    "* RAFT\n",
    "* your own RLHF method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae993bb9",
   "metadata": {
    "id": "ae993bb9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "OzGh9ahKF17h",
   "metadata": {
    "id": "OzGh9ahKF17h"
   },
   "outputs": [],
   "source": [
    "num_digits = 3\n",
    "\n",
    "dataset_size = 64_000\n",
    "train_proportion = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fabd151a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fabd151a",
    "outputId": "e7b36965-8f38-4c49-cf03-0109ab723eca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c054bed",
   "metadata": {
    "id": "6c054bed"
   },
   "source": [
    "## Step 1: Construct a tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "t6aC9uNeIR6C",
   "metadata": {
    "id": "t6aC9uNeIR6C"
   },
   "outputs": [],
   "source": [
    "pad_token=\"[PAD]\"\n",
    "eos_token=\"[EOS]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "g2QiF-otFur3",
   "metadata": {
    "id": "g2QiF-otFur3"
   },
   "outputs": [],
   "source": [
    "class character_level_tokenizer:\n",
    "    \"\"\"\n",
    "    character-level\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.vocab = [str(x) for x in range(10)] + [\"+\", \"=\"] + [pad_token, eos_token]\n",
    "        self.token_to_id = {v : k for k, v in enumerate(self.vocab)}\n",
    "        self.id_to_token = {k : v for k, v in enumerate(self.vocab)}\n",
    "        self.ntokens = len(self.vocab)\n",
    "        self.pattern = f\"[^{re.escape(''.join(self.vocab))}]\"\n",
    "\n",
    "    def clean(self, text):\n",
    "        \"\"\"\n",
    "        removes all characters not in the vocabulary\n",
    "        \"\"\"\n",
    "        out = re.sub(self.pattern, \"\", text)\n",
    "        return out\n",
    "\n",
    "    def pre_tokenization(self, text):\n",
    "        \"\"\"\n",
    "        character-level\n",
    "        \"\"\"\n",
    "        return [c for c in text]\n",
    "\n",
    "    def encode(self, text):\n",
    "        text_list = self.pre_tokenization(self.clean(text))\n",
    "        return [self.token_to_id[c] for c in text_list]\n",
    "\n",
    "    def decode(self, token_list):\n",
    "        return \"\".join([self.id_to_token[x] for x in token_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "QuCc6jF5F8hK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QuCc6jF5F8hK",
    "outputId": "e42dddaa-dacd-471e-b7d0-48f17004dd87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = character_level_tokenizer()\n",
    "ntokens = tokenizer.ntokens\n",
    "ntokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8FXW2K-1Jd-P",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8FXW2K-1Jd-P",
    "outputId": "fff6c129-8820-4b3c-8caa-b43710370098"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2, 10, 4, 2, 11], '12+42=')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"12 + 42 =\"\n",
    "inputs = tokenizer.encode(prompt)\n",
    "inputs, tokenizer.decode(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491af297",
   "metadata": {
    "id": "491af297"
   },
   "source": [
    "## Step 2: Create a dataset for arithmetic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "daa90f31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "daa90f31",
    "outputId": "c23f0b74-6948-43a9-9e6f-5846f4b325b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('616+989=', '1605')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_datapoint(num_digits = 3):\n",
    "    a_list = [random.randint(0, 9) for _ in range(num_digits)]\n",
    "    b_list = [random.randint(0, 9) for _ in range(num_digits)]\n",
    "    a_int = int(\"\".join([str(x) for x in a_list]))\n",
    "    b_int = int(\"\".join([str(x) for x in b_list]))\n",
    "    a_str = \"\".join([str(x) for x in a_list])\n",
    "    b_str = \"\".join([str(x) for x in b_list])\n",
    "    sum_int = a_int + b_int\n",
    "    return (a_str + \"+\" + b_str + \"=\", str(sum_int))\n",
    "\n",
    "sample_datapoint(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6e861d2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6e861d2",
    "outputId": "7b639165-7809-4f2d-a067-f21547c293b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('681+848=', '1529'),\n",
       " ('034+937=', '971'),\n",
       " ('912+897=', '1809'),\n",
       " ('222+748=', '970')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for _ in range(dataset_size):\n",
    "    data.append(sample_datapoint(num_digits))\n",
    "data[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fee85050",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fee85050",
    "outputId": "69def39c-084c-4074-f296-908925038748"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57600, 6400)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = data[: int(train_proportion * dataset_size)]\n",
    "data_test = data[int(train_proportion * dataset_size):]\n",
    "\n",
    "len(data_train),len(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37200598",
   "metadata": {
    "id": "37200598"
   },
   "source": [
    "## Step 3: Construct a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91674239",
   "metadata": {
    "id": "91674239"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    r\"\"\"Inject some information about the relative or absolute position of the tokens in the sequence.\n",
    "        The positional encodings have the same dimension as the embeddings, so that the two can be summed.\n",
    "        Here, we use sine and cosine functions of different frequencies.\n",
    "    .. math:\n",
    "        \\text{PosEncoder}(pos, 2i) = sin(pos/10000^(2i/d_model))\n",
    "        \\text{PosEncoder}(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n",
    "        \\text{where pos is the word position and i is the embed idx)\n",
    "    Args:\n",
    "        d_model: the embed dim (required).\n",
    "        dropout: the dropout value (default=0.1).\n",
    "        max_len: the max. length of the incoming sequence (default=5000).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        r\"\"\"Inputs of forward function\n",
    "        Args:\n",
    "            x: the sequence fed to the positional encoder model (required).\n",
    "        Shape:\n",
    "            x: [sequence length, batch size, embed dim]\n",
    "            output: [sequence length, batch size, embed dim]\n",
    "        \"\"\"\n",
    "\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4eb278ab",
   "metadata": {
    "id": "4eb278ab"
   },
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Transformer):\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__(d_model=ninp,\n",
    "                                               nhead=nhead,\n",
    "                                               dim_feedforward=nhid,\n",
    "                                               num_encoder_layers=nlayers)\n",
    "        self.input_emb = nn.Embedding(ntoken, ninp)\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        self.decoder = nn.Linear(ninp, ntoken)\n",
    "\n",
    "        self.ninp = ninp\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        nn.init.uniform_(self.input_emb.weight, -initrange, initrange)\n",
    "        nn.init.zeros_(self.decoder.bias)\n",
    "        nn.init.uniform_(self.decoder.weight, -initrange, initrange)\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        return torch.log(torch.tril(torch.ones(sz,sz)))\n",
    "\n",
    "    def forward(self, src):\n",
    "        mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "        self.src_mask = mask\n",
    "\n",
    "        src = self.input_emb(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "        output_enc = self.encoder(src, mask=self.src_mask)\n",
    "        output_dec = self.decoder(output_enc)\n",
    "        return F.log_softmax(output_dec, dim=-1), output_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d568cc4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d568cc4",
    "outputId": "7677a7ea-d06a-46a8-85f3-44274cc008a5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danube/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-7): 8 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=64, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): Linear(in_features=128, out_features=14, bias=True)\n",
       "  (input_emb): Embedding(14, 128)\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TransformerModel(ntoken = ntokens,\n",
    "                         ninp = 128,\n",
    "                         nhead = 16,\n",
    "                         nhid = 64,\n",
    "                         nlayers = 8)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6PmJSo95N4C",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6PmJSo95N4C",
    "outputId": "f0177342-43b6-46c6-b079-aab40db326d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 668942\n"
     ]
    }
   ],
   "source": [
    "print(\"number of parameters: {}\".format(sum([x.numel() for x in model.parameters()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e35d113",
   "metadata": {
    "id": "2e35d113"
   },
   "source": [
    "### Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f2f06e0",
   "metadata": {
    "id": "8f2f06e0"
   },
   "outputs": [],
   "source": [
    "def generate(model, prompts, new_tokens = 5, mode = \"greedy\", num_samples = 1, temperature = 0.8):\n",
    "    input_tensor = torch.repeat_interleave(prompts, repeats = num_samples, dim = 1).to(device)\n",
    "    # (prompt_length, batch_size * num_samples)\n",
    "    for _ in range(new_tokens):\n",
    "        output, _ = model(input_tensor) # (prompt_length, batch_size * num_samples, ntokens)\n",
    "        logits = output[-1,:,:] # (batch_size * num_samples, ntokens)\n",
    "        if mode == \"greedy\":\n",
    "            tokens = torch.argmax(logits, -1).view((1,-1)) # (1, batch_size * num_samples)\n",
    "        else: # mode == \"sampling\"\n",
    "            logits /= temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            tokens = torch.multinomial(probs, num_samples = 1).view((1,-1)) # (1, batch_size * num_samples)\n",
    "        input_tensor = torch.cat((input_tensor, tokens), 0)\n",
    "    return input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d76d1b19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d76d1b19",
    "outputId": "7c084e50-8269-4f24-859a-4f95f8bd143d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2, 10,  3, 11, 12, 10, 10, 12, 10]], device='cuda:0'),\n",
       " '2+3=[PAD]++[PAD]+')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "prompt = \"2+3=\"\n",
    "prompt_tensor = torch.tensor(tokenizer.encode(prompt)).view((-1,1))\n",
    "output = generate(model, prompt_tensor).view((1,-1))\n",
    "output, tokenizer.decode(output[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5581c7f-822d-43fd-a29a-5f796ab61641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2],\n",
       "        [10],\n",
       "        [ 3],\n",
       "        [11]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00954ddc",
   "metadata": {
    "id": "00954ddc"
   },
   "outputs": [],
   "source": [
    "def pad(token_list, type_list = \"prompts\"):\n",
    "    max_length = max([len(x) for x in token_list])\n",
    "    out = []\n",
    "    for x in token_list:\n",
    "        if type_list == \"prompts\":\n",
    "            out.append([tokenizer.token_to_id[pad_token]] * (max_length - len(x)) + x)\n",
    "        if type_list == \"answers\":\n",
    "            out.append(x + [tokenizer.token_to_id[eos_token]] + [tokenizer.token_to_id[pad_token]] * (max_length - len(x)))\n",
    "    return out, max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c84beab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2c84beab",
    "outputId": "3e53a680-31e1-4cd6-8ce0-d96009def972"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[PAD][PAD]1+1=', '21+35='], ['2[EOS][PAD]', '56[EOS]'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = [tokenizer.encode(\"1+1=\"), tokenizer.encode(\"21+35=\")]\n",
    "answers = [tokenizer.encode(\"2\"), tokenizer.encode(\"56\")]\n",
    "padded_prompts, _ = pad(prompts, \"prompts\")\n",
    "padded_answers, _ = pad(answers, \"answers\")\n",
    "padded_prompts, padded_answers\n",
    "[tokenizer.decode(p) for p in padded_prompts], [tokenizer.decode(p) for p in padded_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "264f9227",
   "metadata": {
    "id": "264f9227"
   },
   "outputs": [],
   "source": [
    "def get_batch(split, i, batch_size):\n",
    "    data = data_train if split == 'train' else data_test\n",
    "\n",
    "    prompts = [data[i][0] for i in range(i, i + batch_size)]\n",
    "    encoded_prompts = [tokenizer.encode(prompt) for prompt in prompts]\n",
    "    padded_prompts, prompt_length = pad(encoded_prompts, \"prompts\")\n",
    "\n",
    "    answers = [data[i][1] for i in range(i, i + batch_size)]\n",
    "    encoded_answers = [tokenizer.encode(answer) for answer in answers]\n",
    "    padded_answers, answers_length = pad(encoded_answers, \"answers\")\n",
    "\n",
    "    X = torch.stack([torch.tensor(x) for x in padded_prompts], 1)\n",
    "    Y = torch.stack([torch.tensor(x) for x in padded_answers], 1)\n",
    "    return X, Y, prompt_length, answers_length, prompts, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91e281ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91e281ad",
    "outputId": "2a97779d-08e9-485a-9588-07e699dc6b77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 16]), torch.Size([5, 16]), 8, 4, '661+105=', '766')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y, prompt_length, answers_length, prompts, answers = get_batch(\"train\", 43, 16)\n",
    "X.shape, Y.shape, prompt_length, answers_length, prompts[0], answers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113e1fd1",
   "metadata": {
    "id": "113e1fd1"
   },
   "source": [
    "## Step 4: Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "KfmcSdPwp3K6",
   "metadata": {
    "id": "KfmcSdPwp3K6"
   },
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cfcd10a",
   "metadata": {
    "id": "1cfcd10a"
   },
   "outputs": [],
   "source": [
    "def evaluate(batch_size = batch_size):\n",
    "    # Turn on evaluation mode disables dropout.\n",
    "    model.eval()\n",
    "    correct = 0.\n",
    "    with torch.no_grad():\n",
    "        for batch, i in enumerate(range(0, len(data_test) - 1, batch_size)):\n",
    "            prompts, target_answers, prompt_length, answers_length, _, _ = get_batch(\"test\", i, batch_size)\n",
    "            prompts = prompts.to(device) # (prompt_length, batch_size)\n",
    "            target_answers = target_answers.to(device) # (answers_length + 1, batch_size)\n",
    "            output = generate(model, prompts, answers_length + 1) # (prompt_length + answers_length + 1, batch_size)\n",
    "            answers_tokens = output[prompt_length:, :] # (answers_length + 1, batch_size), contains tokens\n",
    "            equality_test = answers_tokens == target_answers # (answers_length + 1, batch_size), contains boolean values\n",
    "            correct += torch.all(equality_test, axis=0).float().sum()\n",
    "        accuracy = correct / len(data_test)\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac335b05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ac335b05",
    "outputId": "1355d497-45f0-440a-90b8-30a7f2818091"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c54061a",
   "metadata": {
    "id": "4c54061a"
   },
   "source": [
    "## Step 5: Train the model, classical approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b827e567",
   "metadata": {
    "id": "b827e567"
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b140ba3",
   "metadata": {
    "id": "5b140ba3"
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 16\n",
    "learning_rate = 8e-4\n",
    "\n",
    "reporting_per_epoch = 5\n",
    "log_interval = len(data_train) // (reporting_per_epoch + 1)\n",
    "assert(log_interval % batch_size == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3638a75d",
   "metadata": {
    "id": "3638a75d"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    best_test_accuracy = None\n",
    "    test_accuracy = evaluate()\n",
    "    print('-' * 89)\n",
    "    print('| initialisation | test accuracy {:5.2f}'.format(test_accuracy))\n",
    "    print('-' * 89)\n",
    "    for epoch in range(1, epochs+1):\n",
    "        epoch_start_time = time.time()\n",
    "        total_loss = 0.\n",
    "        start_time = time.time()\n",
    "        for batch, i in enumerate(range(0, len(data_train) - 1, batch_size)):\n",
    "            prompts, target_answers, prompt_length, answers_length, _, _ = get_batch(\"train\", i, batch_size)\n",
    "            prompts = prompts.to(device) # (prompt_length, batch_size)\n",
    "            target_answers = target_answers.to(device) # (answers_length + 1, batch_size)\n",
    "            input_tensor = torch.cat((prompts, target_answers), 0) # (prompt_length + answers_length + 1, batch_size)\n",
    "            model.zero_grad()\n",
    "            output, _ = model(input_tensor) # (prompt_length + answers_length + 1, batch_size, ntokens)\n",
    "            output_answers = output[prompt_length-1:-1,:,:].reshape(-1, ntokens) # ((answers_length + 1) * batch_size, ntokens)\n",
    "            target_answers = target_answers.view(-1)\n",
    "            loss = F.cross_entropy(output_answers, target_answers)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if i % log_interval == 0 and batch > 0:\n",
    "                cur_loss = total_loss / log_interval\n",
    "                elapsed = time.time() - start_time\n",
    "                print('| {:5d}/{:5d} batches | ms/batch {:5.2f} | loss {:5.2f} | perplexity {:8.2f}'.format(batch, len(data_train) // batch_size,\n",
    "                                                                                                            elapsed * 1000 / log_interval, cur_loss, math.exp(cur_loss)))\n",
    "                total_loss = 0\n",
    "                start_time = time.time()\n",
    "        test_accuracy = evaluate()\n",
    "        print('-' * 89)\n",
    "        print('| end of epoch {:3d} | time: {:5.2f}s | test accuracy {:5.2f}'.format(epoch, (time.time() - epoch_start_time), test_accuracy))\n",
    "        print('-' * 89)\n",
    "        # Save the model if the test accuracy is the best we've seen so far.\n",
    "        if not best_test_accuracy or test_accuracy < best_test_accuracy:\n",
    "            with open(\"arithmetic.pt\", 'wb') as f:\n",
    "                torch.save(model, f)\n",
    "            best_test_accuracy = test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e2a8490",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4e2a8490",
    "outputId": "492562cc-d243-4314-ab56-d17d41c070ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| initialisation | test accuracy  0.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "|   600/ 3600 batches | ms/batch  1.92 | loss  0.09 | perplexity     1.10\n",
      "|  1200/ 3600 batches | ms/batch  1.86 | loss  0.07 | perplexity     1.08\n",
      "|  1800/ 3600 batches | ms/batch  1.81 | loss  0.07 | perplexity     1.07\n",
      "|  2400/ 3600 batches | ms/batch  1.80 | loss  0.07 | perplexity     1.07\n",
      "|  3000/ 3600 batches | ms/batch  1.77 | loss  0.07 | perplexity     1.07\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 122.32s | test accuracy  0.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "|   600/ 3600 batches | ms/batch  1.78 | loss  0.07 | perplexity     1.07\n",
      "|  1200/ 3600 batches | ms/batch  1.75 | loss  0.06 | perplexity     1.07\n",
      "|  1800/ 3600 batches | ms/batch  1.75 | loss  0.06 | perplexity     1.07\n",
      "|  2400/ 3600 batches | ms/batch  1.72 | loss  0.06 | perplexity     1.07\n",
      "|  3000/ 3600 batches | ms/batch  1.72 | loss  0.06 | perplexity     1.06\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 117.45s | test accuracy  0.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "|   600/ 3600 batches | ms/batch  1.73 | loss  0.07 | perplexity     1.07\n",
      "|  1200/ 3600 batches | ms/batch  1.75 | loss  0.06 | perplexity     1.06\n",
      "|  1800/ 3600 batches | ms/batch  1.74 | loss  0.06 | perplexity     1.06\n",
      "|  2400/ 3600 batches | ms/batch  1.72 | loss  0.05 | perplexity     1.06\n",
      "|  3000/ 3600 batches | ms/batch  1.76 | loss  0.05 | perplexity     1.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 117.50s | test accuracy  0.06\n",
      "-----------------------------------------------------------------------------------------\n",
      "|   600/ 3600 batches | ms/batch  1.80 | loss  0.05 | perplexity     1.05\n",
      "|  1200/ 3600 batches | ms/batch  1.74 | loss  0.04 | perplexity     1.04\n",
      "|  1800/ 3600 batches | ms/batch  1.75 | loss  0.04 | perplexity     1.04\n",
      "|  2400/ 3600 batches | ms/batch  1.75 | loss  0.04 | perplexity     1.04\n",
      "|  3000/ 3600 batches | ms/batch  1.70 | loss  0.03 | perplexity     1.03\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 118.58s | test accuracy  0.15\n",
      "-----------------------------------------------------------------------------------------\n",
      "|   600/ 3600 batches | ms/batch  1.75 | loss  0.03 | perplexity     1.04\n",
      "|  1200/ 3600 batches | ms/batch  1.74 | loss  0.04 | perplexity     1.04\n",
      "|  1800/ 3600 batches | ms/batch  1.72 | loss  0.03 | perplexity     1.03\n",
      "|  2400/ 3600 batches | ms/batch  1.72 | loss  0.03 | perplexity     1.03\n",
      "|  3000/ 3600 batches | ms/batch  1.73 | loss  0.03 | perplexity     1.03\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 116.31s | test accuracy  0.39\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56d9d440",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56d9d440",
    "outputId": "b876390d-4396-4a95-e600-e2230317dbec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540+644=1184[EOS]\t actual result: 1184\n",
      "687+185=872[EOS]\t actual result: 872\n",
      "504+792=1295[EOS]\t actual result: 1296\n",
      "887+025=912[EOS]\t actual result: 912\n",
      "200+564=775[EOS]\t actual result: 764\n",
      "256+441=697[EOS]\t actual result: 697\n",
      "660+030=681[EOS]\t actual result: 690\n",
      "796+187=983[EOS]\t actual result: 983\n",
      "599+686=1284[EOS]\t actual result: 1285\n",
      "507+187=684[EOS]\t actual result: 694\n",
      "163+583=749[EOS]\t actual result: 746\n",
      "224+304=528[EOS]\t actual result: 528\n",
      "790+006=899[EOS]\t actual result: 796\n",
      "268+223=491[EOS]\t actual result: 491\n",
      "151+191=343[EOS]\t actual result: 342\n",
      "559+183=742[EOS]\t actual result: 742\n",
      "138+947=1084[EOS]\t actual result: 1085\n",
      "225+967=1191[EOS]\t actual result: 1192\n",
      "689+042=739[EOS]\t actual result: 731\n",
      "809+127=935[EOS]\t actual result: 936\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "for i in range(20):\n",
    "    prompt, answers = data_test[i]\n",
    "    prompt_tensor = torch.tensor(tokenizer.encode(prompt)).view((-1,1))\n",
    "    output = generate(model, prompt_tensor, len(answers) + 1).view((1,-1))\n",
    "    print(tokenizer.decode(output.tolist()[0]) + \"\\t actual result: \" + answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa4c591",
   "metadata": {
    "id": "cfa4c591"
   },
   "source": [
    "## Step 4 bis: Vanilla GRPO training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff83f72",
   "metadata": {
    "id": "aff83f72"
   },
   "source": [
    "### Custom reward functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c548bf7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3c548bf7",
    "outputId": "b5d45345-22eb-445a-b888-6ad22e96d7b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy_reward(output, answer):\n",
    "    pattern = r\"\\[EOS\\]\"\n",
    "    output = re.sub(pattern, \"\", output)\n",
    "    pattern = r\"(\\[PAD\\])*$\"\n",
    "    output = re.sub(pattern, \"\", output)\n",
    "    return 1. if output == answer else 0.\n",
    "\n",
    "accuracy_reward(\"123[EOS][PAD][PAD]\", \"123\"), accuracy_reward(\"123\", \"124\"),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e1f02762",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e1f02762",
    "outputId": "7271bdf4-4ecf-44ee-ec86-8c815ffaa9a5",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9324546952224053, 0.008064516129032258)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def distance_accuracy_reward(output, answer):\n",
    "    pattern = r\"\\[EOS\\]\"\n",
    "    output = re.sub(pattern, \"\", output)\n",
    "    pattern = r\"(\\[PAD\\])\"\n",
    "    output = re.sub(pattern, \"\", output)\n",
    "    if len(output) > 0:\n",
    "        int_output = int(output)\n",
    "    else:\n",
    "        return 1\n",
    "    int_answer = int(answer)\n",
    "    return abs(int_output - int_answer) / max(int_output, int_answer)\n",
    "\n",
    "distance_accuracy_reward(\"182[PAD]1\", \"123\"), distance_accuracy_reward(\"123[PAD]\", \"124\"),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "b42a0d70",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b42a0d70",
    "outputId": "a79ca9d6-a79b-4640-c172-4db78e433256"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def digit_accuracy_reward(output, answer):\n",
    "    pattern = r\"\\[EOS\\]\"\n",
    "    output = re.sub(pattern, \"\", output)\n",
    "    pattern = r\"(\\[PAD\\])*$\"\n",
    "    output = re.sub(pattern, \"\", output)\n",
    "    return sum(c1 == c2 for (c1,c2) in zip(output, answer)) / max(len(output), len(answer))\n",
    "\n",
    "digit_accuracy_reward(\"123[EOS][PAD][PAD]\", \"123\"), digit_accuracy_reward(\"123[EOS]\", \"123\"),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a41603b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a41603b2",
    "outputId": "33dbf431-4177-4ae3-d36c-08ff8a2261fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 0.0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reward_format(output):\n",
    "    pattern = r\"\\d+\\[EOS\\](\\[PAD\\])*$\"\n",
    "    return 1. if bool(re.match(pattern, output)) else 0.\n",
    "\n",
    "reward_format(\"123[EOS][PAD][PAD]\"), reward_format(\"123[EOS]\"), reward_format(\"123\"),"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4482e411",
   "metadata": {
    "id": "4482e411"
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf764cb0",
   "metadata": {
    "id": "cf764cb0"
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 16\n",
    "learning_rate = 1e-4\n",
    "num_samples = 16\n",
    "temperature = .8\n",
    "\n",
    "reporting_per_epoch = 5\n",
    "log_interval = len(data_train) // (reporting_per_epoch + 1)\n",
    "assert(log_interval % batch_size == 0)\n",
    "\n",
    "reward_fun = digit_accuracy_reward\n",
    "reward_format = reward_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f15cdced",
   "metadata": {
    "id": "f15cdced"
   },
   "outputs": [],
   "source": [
    "def compute_rewards(text_outputs, answers):\n",
    "    repeated_answers = [answer for answer in answers for _ in range(num_samples)]\n",
    "    rewards = torch.tensor(\n",
    "        [0.2 * reward_format(output) + 0.8 * reward_fun(output, answer)\n",
    "         for output, answer in zip(text_outputs, repeated_answers)],\n",
    "        dtype=torch.float32,\n",
    "        device=device\n",
    "    )\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e22be0d4",
   "metadata": {
    "id": "e22be0d4"
   },
   "outputs": [],
   "source": [
    "def calculate_grpo_advantages(rewards):\n",
    "    # reshape rewards to group by prompt\n",
    "    # compute mean and standard deviation for each prompt group\n",
    "    mean_rewards = rewards.view(-1, num_samples).mean(dim=1)\n",
    "    std_rewards = rewards.view(-1, num_samples).std(dim=1)\n",
    "    # expand the means and stds to match the original flat rewards tensor shape\n",
    "    mean_rewards = mean_rewards.repeat_interleave(num_samples, dim=0)\n",
    "    std_rewards = std_rewards.repeat_interleave(num_samples, dim=0)\n",
    "    # normalize rewards to get advantages\n",
    "    advantages = (rewards - mean_rewards) / (std_rewards + 1e-5)\n",
    "    return advantages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "faac5c99",
   "metadata": {
    "id": "faac5c99"
   },
   "outputs": [],
   "source": [
    "def compute_log_probs(model, outputs, prompt_length):\n",
    "    logits, _ = model(outputs)\n",
    "    # logits.shape = (prompt_length + answers_length + 1, batch_size * num_samples, vocab_size)\n",
    "\n",
    "    # we only need the log probabilities for the new tokens\n",
    "    # this introduces a shift: the logits for a position are the predictions for the next token\n",
    "    logits = logits[prompt_length-1:-1, :, :]\n",
    "    # logits.shape = (answers_length + 1, batch_size * num_samples, vocab_size)\n",
    "\n",
    "    # convert raw logits into log probabilities along the vocabulary axis\n",
    "    log_probs = F.log_softmax(logits, dim=-1)\n",
    "    # log_probs.shape = (answers_length + 1, batch_size * num_samples, vocab_size)\n",
    "    return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2612214",
   "metadata": {
    "id": "b2612214"
   },
   "outputs": [],
   "source": [
    "def compute_loss(advantages, log_probs, responses):\n",
    "    # reshape responses from (answers_length + 1, batch_size * num_samples)\n",
    "    # to (answers_length + 1, batch_size * num_samples, 1) for gathering\n",
    "    responses = responses.unsqueeze(-1)\n",
    "    # log_probs.shape = (answers_length + 1, batch_size * num_samples, vocab_size)\n",
    "    # responses.shape = (answers_length + 1, batch_size * num_samples)\n",
    "    # gather the log probability for each token in responses\n",
    "    selected_log_probs = log_probs.gather(dim=-1, index=responses)\n",
    "    # remove the extra last dimension to get back to shape (answers_length + 1, batch_size * num_samples).\n",
    "    selected_log_probs = selected_log_probs.squeeze(-1)\n",
    "\n",
    "    # normalize\n",
    "    selected_log_probs = (selected_log_probs - selected_log_probs.mean(-1, keepdim=True)) / (selected_log_probs.std(-1, keepdim=True) + 1e-5)\n",
    "\n",
    "    # advantages.shape = (batch_size * num_samples)\n",
    "    # we use the same advantages for all tokens in the response\n",
    "    loss = -(advantages.unsqueeze(dim=0) * selected_log_probs).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "824ca075",
   "metadata": {
    "id": "824ca075"
   },
   "outputs": [],
   "source": [
    "def train_vanilla_GRPO(verbose = False):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    best_test_accuracy = None\n",
    "    test_accuracy = evaluate()\n",
    "    print('-' * 89)\n",
    "    print('| initialisation | test accuracy {:5.2f}'.format(test_accuracy))\n",
    "    print('-' * 89)\n",
    "\n",
    "    # switch eval for train model (enables dropout)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        epoch_start_time = time.time()\n",
    "        start_time = time.time()\n",
    "        for batch, i in enumerate(range(0, len(data_train) - 1, batch_size)):\n",
    "\n",
    "            # get a batch of prompts and answers\n",
    "            prompts, _, prompt_length, answers_length, questions, answers = get_batch(\"train\", i, batch_size)\n",
    "            prompts = prompts.to(device) # (prompt_length, batch_size)\n",
    "\n",
    "            # generate samples for each prompt\n",
    "            outputs = generate(model,\n",
    "                               prompts,\n",
    "                               new_tokens = answers_length + 1,\n",
    "                               mode = \"sampling\",\n",
    "                               num_samples = num_samples,\n",
    "                               temperature = temperature)\n",
    "            # outputs.shape = (prompt_length + answers_length + 1, batch_size * num_samples)\n",
    "            text_outputs = [tokenizer.decode(outputs[prompt_length:, i].tolist())\n",
    "                            for i in range(outputs.size(1))]\n",
    "\n",
    "            # compute rewards\n",
    "            rewards = compute_rewards(text_outputs, answers)\n",
    "\n",
    "            # compute advantages\n",
    "            advantages = calculate_grpo_advantages(rewards)\n",
    "\n",
    "            # compute log probabilities\n",
    "            log_probs = compute_log_probs(model, outputs, prompt_length)\n",
    "            # compute loss\n",
    "            responses = outputs[prompt_length:, :]\n",
    "            loss = compute_loss(advantages, log_probs, responses)\n",
    "\n",
    "            # optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if i % log_interval == 0 and batch > 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                print('| {:5d}/{:5d} batches | ms/batch {:5.2f}'.format(batch, len(data_train) // batch_size, elapsed))\n",
    "                if verbose:\n",
    "                    print(\"\\nquestion:\", questions[0],\n",
    "                      \"\\nanswer\", answers[0],\n",
    "                      \"\\noutput:\", text_outputs[:num_samples],\n",
    "                      \"\\nreward:\", rewards[:num_samples],\n",
    "                      \"\\nadvantage:\", advantages[:num_samples], \"\\n\")\n",
    "\n",
    "                start_time = time.time()\n",
    "        test_accuracy = evaluate()\n",
    "        print('-' * 89)\n",
    "        print('| end of epoch {:3d} | time: {:5.2f}s | test accuracy {:5.2f}'.format(epoch, (time.time() - epoch_start_time), test_accuracy))\n",
    "        print('-' * 89)\n",
    "        # Save the model if the test accuracy is the best we've seen so far.\n",
    "        if not best_test_accuracy or test_accuracy < best_test_accuracy:\n",
    "            with open(\"arithmetic_vanilla_GRPO.pt\", 'wb') as f:\n",
    "                torch.save(model, f)\n",
    "            best_test_accuracy = test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b02716ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "id": "b02716ff",
    "outputId": "d3ae59c3-1d5f-4e40-e428-097a04b4edb1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| initialisation | test accuracy  0.97\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_vanilla_GRPO(verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aeVn935w5BSp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aeVn935w5BSp",
    "outputId": "2014648b-68e6-4af6-ce9c-b28a3d580c7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596+042=638[EOS]\t actual result: 638\n",
      "361+026=387[EOS]\t actual result: 387\n",
      "476+468=944[EOS]\t actual result: 944\n",
      "183+460=643[EOS]\t actual result: 643\n",
      "181+472=653[EOS]\t actual result: 653\n",
      "197+314=511[EOS]\t actual result: 511\n",
      "107+344=451[EOS]\t actual result: 451\n",
      "463+717=1180[EOS]\t actual result: 1180\n",
      "853+302=1155[EOS]\t actual result: 1155\n",
      "733+425=1158[EOS]\t actual result: 1158\n",
      "666+642=1308[EOS]\t actual result: 1308\n",
      "429+503=932[EOS]\t actual result: 932\n",
      "669+763=1432[EOS]\t actual result: 1432\n",
      "099+807=906[EOS]\t actual result: 906\n",
      "693+680=1373[EOS]\t actual result: 1373\n",
      "969+035=1004[EOS]\t actual result: 1004\n",
      "266+340=606[EOS]\t actual result: 606\n",
      "349+083=432[EOS]\t actual result: 432\n",
      "279+313=592[EOS]\t actual result: 592\n",
      "804+300=1104[EOS]\t actual result: 1104\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "for i in range(20):\n",
    "    prompt, answers = data_test[i]\n",
    "    prompt_tensor = torch.tensor(tokenizer.encode(prompt)).view((-1,1))\n",
    "    output = generate(model, prompt_tensor, len(answers) + 1).view((1,-1))\n",
    "    print(tokenizer.decode(output.tolist()[0]) + \"\\t actual result: \" + answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68652de-7184-4200-a8bc-7811ff1d7d8f",
   "metadata": {},
   "source": [
    "## DPO (Direct Preference Optimization)\n",
    "The goal is to implement the RL training framework as in [Direct Preference Optimization: \n",
    "Your Language Model is Secretly a Reward Mode](https://arxiv.org/pdf/2305.18290).\n",
    "\n",
    "\n",
    "The reason why I've chosen this method is because it appeared to me to be the most \"original\" one, in the sense that we don't learn directly a reward model upon which we will learn a policy. But we will rather learns a policy that implicitly learn to maximize this reward.g\r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af2df14f-b97a-40d4-87c8-cdecf9e290cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "batch_size = 16\n",
    "learning_rate = 1e-4\n",
    "num_samples = 16\n",
    "temperature = .8\n",
    "epsilon = 0.2\n",
    "reporting_per_epoch = 5\n",
    "n_trajectoris = 10000\n",
    "log_interval = len(data_train) // (reporting_per_epoch + 1)\n",
    "assert(log_interval % batch_size == 0)\n",
    "\n",
    "reward_fun = digit_accuracy_reward\n",
    "reward_format = reward_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "39baef30-62f1-4a61-afa2-63cf23d34fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModel(ntoken = ntokens,\n",
    "                         ninp = 128,\n",
    "                         nhead = 16,\n",
    "                         nhid = 64,\n",
    "                         nlayers = 8)\n",
    "model.to(device)\n",
    "with open(\"arithmetic.pt\", 'rb') as f:\n",
    "    model = torch.load(f, weights_only = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d07d0c-90dc-42cf-b792-493a0e3b2f07",
   "metadata": {},
   "source": [
    "### 1. Generate a dataset of pairs\n",
    "\n",
    "We'll generate a dataset, where a sample = [prompt, answer 1, answer2].\n",
    "\n",
    "The answer 1 is better than answer 2 according to the function compute_rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "8efe28d1-068a-414c-8428-6395898b3806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rewards_dpo(text_outputs, answers):\n",
    "    repeated_answers = [answer for answer in answers for _ in range(num_samples)]\n",
    "    rewards = torch.tensor(\n",
    "        [distance_accuracy_reward(output, answer)\n",
    "         for output, answer in zip(text_outputs, repeated_answers)],\n",
    "        dtype=torch.float32,\n",
    "        device=device\n",
    "    )\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "9db79b8b-e45a-4e3f-b8b0-c563176b3a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def generate_dataset(model):\n",
    "    dataset = []\n",
    "    for batch, i in tqdm(enumerate(range(0, len(data_train) - 1, batch_size))):\n",
    "        prompts, _, prompt_length, answers_length, questions, answers = get_batch(\"train\", i, batch_size)\n",
    "        prompts = prompts.to(device) # prompt_length, batch_size\n",
    "        outputs_ref = generate(model,\n",
    "                               prompts,\n",
    "                               new_tokens = answers_length + 1,\n",
    "                               mode = \"sampling\",\n",
    "                               num_samples = 2,\n",
    "                               temperature = temperature)\n",
    "        text_outputs_ref = [tokenizer.decode(outputs_ref[prompt_length:, i].tolist())\n",
    "                            for i in range(outputs_ref.size(1))]\n",
    "        rewards = compute_rewards_dpo(text_outputs_ref, answers) \n",
    "\n",
    "        j = 0\n",
    "        for i in range(0, len(text_outputs_ref), 2):\n",
    "            if rewards[i] > rewards[i + 1]: # This is not really a reward, more like a score.\n",
    "                left = outputs_ref[prompt_length:, i + 1]\n",
    "                right = outputs_ref[prompt_length:, i ]\n",
    "            else:\n",
    "                left = outputs_ref[prompt_length:, i ]\n",
    "                right = outputs_ref[prompt_length:, i + 1]\n",
    "            dataset.append([prompts[:, j], left, right])\n",
    "            j += 1\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "71b17d2d-b42b-46a3-a927-2c02de0cec16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3600it [03:50, 15.64it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_dpo = generate_dataset(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "ff79b8c8-79fc-4caf-b896-ad4127748e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473+484=\n",
      "960[EOS][PAD]\n",
      "955[EOS][PAD]\n"
     ]
    }
   ],
   "source": [
    "i = random.randint(0, len(dataset_dpo))\n",
    "print(tokenizer.decode(dataset_dpo[i ][0].tolist()))\n",
    "print(tokenizer.decode(dataset_dpo[i ][1].tolist()))\n",
    "print(tokenizer.decode(dataset_dpo[i ][2].tolist()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2750774f-07f7-47f7-8210-fccf9ceb8b70",
   "metadata": {},
   "source": [
    "### 2. Compute the loss for DPO\n",
    "\n",
    "The loss is defined only in terms of policy (ie, transformers models).\n",
    "\n",
    "Given:\n",
    "* a policy of reference $ \\pi_{ref} $\n",
    "* a policy $ \\pi_{\\theta} $ that we learn.\n",
    "* a dataset $\\cal{D}(x, y_b, y_w) $\n",
    "\n",
    "We can formulate a maximum likelihood objective for $ \\pi_{\\theta} $ as :\n",
    "$\\mathcal{L}_{\\text{DPO}}(\\pi_{\\theta}; \\pi_{\\text{ref}}) =\r\n",
    "- \\mathbb{E}_{(x, y_w, y_l) \\sim \\mathcal{D}} \\left[\r\n",
    "\\log \\sigma \\left( \\beta \\log \\frac{\\pi_{\\theta}(y_w \\mid x)}{\\pi_{\\text{ref}}(y_w \\mid x)}\r\n",
    "- \\beta \\log \\frac{\\pi_{\\theta}(y_l \\mid x)}{\\pi_{\\text{ref}}(y_l \\mid x)} \\right)\r\n",
    "\\right]$ght]$ht]$ri$$]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "36c37a45-83c9-46ba-a65a-e78223a0b1d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_loss_dpo(log_probs, log_probs_ref, beta = 1):\n",
    "    return -torch.mean(torch.log(torch.sigmoid(beta * (log_probs[:, 0] - log_probs_ref[: , 0]) - beta * (log_probs[:, 1] - log_probs_ref[:, 1]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8df394-34bc-4a34-89ee-0a3949df42ca",
   "metadata": {},
   "source": [
    "### 3. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "12521253-c642-4e6e-96c3-066da33efd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy \n",
    "def train_DPO(verbose = False):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    best_test_accuracy = None\n",
    "    test_accuracy = evaluate()\n",
    "    print('-' * 89)\n",
    "    print('| initialisation | test accuracy {:5.2f}'.format(test_accuracy))\n",
    "    print('-' * 89)\n",
    "    \n",
    "    # switch eval for train model (enables dropout)\n",
    "    model.train()\n",
    "    j = 0\n",
    "    for epoch in range(1, epochs+1):\n",
    "        epoch_start_time = time.time()\n",
    "        start_time = time.time()\n",
    "        for i in tqdm(range(0, len(dataset_dpo), batch_size)):\n",
    "            prompts = torch.tensor([], device = device, dtype = torch.long)\n",
    "            answers1 = torch.tensor([], device = device, dtype = torch.long)\n",
    "            answers2 = torch.tensor([], device = device, dtype = torch.long)\n",
    "            for j in range(i, i + batch_size):\n",
    "                prompts = torch.cat((prompts, dataset_dpo[j][0].unsqueeze(1)), dim = 1)\n",
    "\n",
    "                answers1 = torch.cat((answers1, dataset_dpo[j][1].unsqueeze(1)), dim = 1)\n",
    "                answers2 = torch.cat((answers2, dataset_dpo[j][2].unsqueeze(1)), dim = 1)\n",
    "            prompts = prompts.view(-1, batch_size)\n",
    "            answers1 = answers1.view(-1, batch_size)\n",
    "            answers2 = answers2.view(-1, batch_size)\n",
    "            # get a batch of prompts and answers\n",
    "            input_tensor = torch.repeat_interleave(prompts, repeats = 2, dim = 1).to(device)\n",
    "            outputs = generate(model,\n",
    "                               prompts,\n",
    "                               new_tokens = answers_length + 1,\n",
    "                               mode = \"sampling\",\n",
    "                               num_samples = 2,\n",
    "                               temperature = temperature)\n",
    "            answers = torch.cat((answers1, answers2), dim = 1)\n",
    "            outputs_ref = torch.cat((input_tensor, answers), 0)\n",
    "\n",
    "            # compute rewards\n",
    "            #rewards = compute_rewards(text_outputs, answers)\n",
    "            #print(rewards)\n",
    "            #return\n",
    "            # compute advantages\n",
    "            #advantages = calculate_grpo_advantages(rewards)\n",
    "\n",
    "            # compute log probabilities\n",
    "\n",
    "            log_probs = compute_log_probs(model, outputs, prompt_length).view(-1, 2, batch_size, 14)\n",
    "            log_probs_ref = compute_log_probs(model_ref, outputs_ref, prompt_length).view(-1, 2, batch_size, 14)\n",
    "            \n",
    "                \n",
    "            #log_probs_ref = compute_log_probs(model_ref, \n",
    "            # compute loss\n",
    "            responses = outputs[prompt_length:, :]\n",
    "            loss = compute_loss_dpo(log_probs, log_probs_ref)\n",
    "\n",
    "            # optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if i % log_interval == 0 :\n",
    "                elapsed = time.time() - start_time\n",
    "                if verbose:\n",
    "                    print(\"\\nquestion:\", questions[0],\n",
    "                      \"\\nanswer\", answers[0],\n",
    "                      \"\\noutput:\", text_outputs[:num_samples],\n",
    "                      \"\\nreward:\", rewards[:num_samples],\n",
    "                      \"\\nadvantage:\", advantages[:num_samples], \"\\n\")\n",
    "\n",
    "                start_time = time.time()\n",
    "        test_accuracy = evaluate()\n",
    "        print('-' * 89)\n",
    "        print('| end of epoch {:3d} | time: {:5.2f}s | test accuracy {:5.2f}'.format(epoch, (time.time() - epoch_start_time), test_accuracy))\n",
    "        print('-' * 89)\n",
    "        # Save the model if the test accuracy is the best we've seen so far.\n",
    "        if not best_test_accuracy or test_accuracy < best_test_accuracy:\n",
    "            with open(\"arithmetic_dpo.pt\", 'wb') as f:\n",
    "                torch.save(model, f)\n",
    "            best_test_accuracy = test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "ae97a04e-0c27-4bc9-ba25-467460931325",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = copy.deepcopy(model_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "d1a0706e-b94b-4478-affb-0e90a8607b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ref = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "a4ee1247-c501-44fc-be51-07d989b2c51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| initialisation | test accuracy  0.39\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 3600/3600 [06:55<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 431.71s | test accuracy  0.00\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 3600/3600 [06:26<00:00,  9.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 403.86s | test accuracy  0.00\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_DPO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "77b1f750-af04-471f-9258-b77918ca987b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540+644=11843\t actual result: 1184\n",
      "687+185=7774\t actual result: 872\n",
      "504+792=12943\t actual result: 1296\n",
      "887+025=9013\t actual result: 912\n",
      "200+564=7764\t actual result: 764\n",
      "256+441=6993\t actual result: 697\n",
      "660+030=6893\t actual result: 690\n",
      "796+187=9883\t actual result: 983\n",
      "599+686=12843\t actual result: 1285\n",
      "507+187=6893\t actual result: 694\n",
      "163+583=7443\t actual result: 746\n",
      "224+304=5233\t actual result: 528\n",
      "790+006=7994\t actual result: 796\n",
      "268+223=4994\t actual result: 491\n",
      "151+191=3343\t actual result: 342\n",
      "559+183=7434\t actual result: 742\n",
      "138+947=10843\t actual result: 1085\n",
      "225+967=11933\t actual result: 1192\n",
      "689+042=7333\t actual result: 731\n",
      "809+127=9034\t actual result: 936\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "for i in range(20):\n",
    "    prompt, answers = data_test[i]\n",
    "    prompt_tensor = torch.tensor(tokenizer.encode(prompt)).view((-1,1))\n",
    "    output = generate(model, prompt_tensor, len(answers) + 1).view((1,-1))\n",
    "    print(tokenizer.decode(output.tolist()[0]) + \"\\t actual result: \" + answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601e6d49-7126-4bbb-b8df-37046ca80044",
   "metadata": {},
   "source": [
    "Model's accuracy has completely collapsed, and it always outputs one digit too many,  and there can be different reasons for this to happen:\n",
    "* Maybe start with a better model (Accuracy over 60 %).\n",
    "* Increase parameter Beta.\n",
    "* The loss I've implemented can be wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f700e9-0ee3-44c8-a74f-96e7188266fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Signal",
   "language": "python",
   "name": "signal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

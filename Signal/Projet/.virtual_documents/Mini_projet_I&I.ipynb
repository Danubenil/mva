!pip uninstall tslearn



!pip install tslearn
!pip install pesq
!pip install pystoi



! pip install torchvision


import IPython
import os
from scipy.io import wavfile
from tslearn.metrics import dtw, dtw_path
from scipy.signal import stft
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from pesq import pesq
from pystoi.stoi import stoi
from torch.utils.data import Dataset
import os
from tqdm import tqdm
import pickle
from torch.utils.data import random_split
import torchaudio.transforms as T
import torch.nn.functional as F
from pesq import pesq
from pystoi.stoi import stoi


print("GPU is", "available" if torch.cuda.is_available() else "not available")


# Pour notebook en local
chemin = "."
# Fonction pour charger les données
def charger_donnees(dossier):
    list_to_fill = []
    # Parcourir les fichiers .wav dans le dossier
    for fichier in os.listdir(dossier):
        if fichier.endswith(".wav"):
            chemin_complet = os.path.join(dossier, fichier)
            samplerate, data = wavfile.read(chemin_complet)
            list_to_fill.append({
                "nom": fichier,
                "samplerate": samplerate,
                "data": data})
    return sorted(list_to_fill, key=lambda d: d["nom"])

device = "cuda" if torch.cuda.is_available() else "cpu"

def train(model, lr = 0.005, n_epochs = 100, print_step = 10, proportion = 0.5, type_loss = "MSE"):
    optimizer = torch.optim.Adam(model.parameters(), lr = lr)
    if type_loss.upper() == "L1":
        loss = torch.nn.L1Loss()
    else:
        loss = torch.nn.MSELoss()
    losses_eval = []
    pbar = tqdm(range(n_epochs))
    scaler = torch.amp.GradScaler()

    for i in pbar:
        
        model.train()
        optimizer.zero_grad()
        l = 0
        j = 0
        #with torch.amp.autocast(device):
        for batch, true_val in train_loader:
            if j * len(batch) > proportion * len(dataset_train):
                break
            output = model(batch)
            l += loss(output, true_val)
            j += 1
        l.backward()
        optimizer.step()
        model.eval()
        with torch.no_grad():
            l = 0
            for batch, true_val in val_loader:
                output = model(batch)
                l += loss(output, true_val)
            losses_eval.append(l)
            if i % print_step == 0:
                print(f"Loss eval :  {l:.2f}")
        pbar.set_description("Processing with loss : " + str(losses_eval[-1].item()))
    return losses_eval


class DatasetVoice(Dataset):
    def __init__(self, chemin = ".", type_ = "train",  nb_samples = 1000, transform = None):
        types = ["train", "test", "train_small"]
        if type_ not in types:
            return Exception("Please provide a correct type among those : " + str(types)) 
        dicX, dicY = charger_donnees(os.path.join(chemin, "packet_loss", type_ )), charger_donnees(os.path.join(chemin, "voice_origin", type_ ))
        
        split = len(dicX[0]["data"]) // nb_samples
        self.X = torch.zeros(len(dicX) * split, len(dicX[0]["data"]) // split)#.to(device)
        self.y = torch.zeros(len(dicY) * split, len(dicY[0]["data"]) // split)#.to(device)
        step = len(dicX[0]["data"]) // split
        for i in tqdm(range(0, len(dicX))):
            dicX[i]["data"] = dicX[i]["data"] / np.max(np.abs(dicX[i]["data"]))
            dicY[i]["data"] = dicY[i]["data"] / np.max(np.abs(dicY[i]["data"]))
            splitsX = [dicX[i]["data"][j:j+step] for j in range(0, len(dicX[i]["data"]), step)]
            splitsY = [dicY[i]["data"][j:j+step] for j in range(0, len(dicY[i]["data"]), step)]
            if split == 1:
                splits = [dicX[i]["data"]]
            for j in range(len(splitsX)):
                self.X[i * split +  j] = torch.from_numpy(splitsX[j])#.to(device)
                self.y[i * split+ j] = torch.from_numpy(splitsY[j])#.to(device)
        self.X = self.X.to(device)
        self.y = self.y.to(device)
        self.transform = transform.to(device)
    def __getitem__(self, i):
        feature, target = self.X[i], self.y[i]
        if self.transform:
            feature = self.transform(feature,)
            target = self.transform(target,)
            feature_abs = (feature.abs())
            target_abs = (target.abs())
            feature_abs /= feature_abs.max()
            target_abs /= target_abs.max()
            feature_angle = feature.angle()
            target_angle = target.angle()
            return (feature_abs, feature_angle,
            target_abs, target_angle)
        return feature, target
    def __len__(self):
        return len(self.X)








# Pour notebook en local
chemin = "."


# Charger le drive
from google.colab import drive
drive.mount('/content/drive')
# Chemin du répertoire de mon drive contenant les données
chemin = '/content/drive/MyDrive/Colab Notebooks/S1 I&I/mini-projet/'


# Fonction pour charger les données
def charger_donnees(dossier):
    list_to_fill = []
    # Parcourir les fichiers .wav dans le dossier
    for fichier in os.listdir(dossier):
        if fichier.endswith(".wav"):
            chemin_complet = os.path.join(dossier, fichier)
            samplerate, data = wavfile.read(chemin_complet)
            list_to_fill.append({
                "nom": fichier,
                "samplerate": samplerate,
                "data": data})
    return sorted(list_to_fill, key=lambda d: d["nom"])


dossier_packetloss_train, dossier_voiceorigin_train = chemin + '/packet_loss/train', chemin + '/voice_origin/train'
dossier_packetloss_test, dossier_voiceorigin_test = chemin + '/packet_loss/test', chemin + '/voice_origin/test'

X_train, Y_train = charger_donnees(dossier_packetloss_train), charger_donnees(dossier_voiceorigin_train)
X_test, Y_test = charger_donnees(dossier_packetloss_test), charger_donnees(dossier_voiceorigin_test)

print(f"Ensemble d'entraînement : {len(X_train)} fichiers avec pertes de paquets et {len(Y_train)} fichiers de voix originaux.")
print(f"Ensemble de test : {len(X_test)} fichiers avec pertes de paquets et {len(Y_test)} fichiers de voix originaux.")


# On vérifie qu'il y a bien une unique sample rate (à enlever ?)
samplerates = []
for dic in X_train : samplerates.append(dic['samplerate'])
for dic in Y_train : samplerates.append(dic['samplerate'])
for dic in X_test : samplerates.append(dic['samplerate'])
for dic in Y_test : samplerates.append(dic['samplerate'])
print("La liste des differentes samplerates du dataset de train et test est :", np.unique(np.array(samplerates)))
samplerate = samplerates[0]


idx = 43


IPython.display.Audio(X_train[idx]['data'], rate=samplerate) #with packet loss



IPython.display.Audio(Y_train[idx]['data'], rate=samplerate) #without (original sound)


idx = 43
plt.figure()
plt.plot(Y_train[idx]['data'], label ="original voice")
plt.plot(X_train[idx]['data'], label = "packet loss")
plt.grid(alpha=0.3)
plt.legend()
plt.show()





# Fonction pour normaliser un signal
def normaliser(signal):
    max_val = np.max(np.abs(signal))
    return signal / max_val

for dic in X_train : dic['data'] = normaliser(dic['data'])
for dic in Y_train : dic['data'] = normaliser(dic['data'])
for dic in X_test : dic['data'] = normaliser(dic['data'])
for dic in Y_test : dic['data'] = normaliser(dic['data'])


idx = 43

# Signal analysis
signal_og = Y_train[idx]['data']
signal_loss = X_train[idx]['data']
indices = []
for i in range(len(signal_og)):
  if abs(signal_og[i] - signal_loss[i]) > 1e-6:
        indices.append(i)
bursts = np.nan * np.ones(len(signal_og))
for i in indices:
  bursts[i] = -1

bursts_estimes = np.nan * np.ones(len(signal_loss))
indices_paquets_perdus = np.where(signal_loss == 0.0)
bursts_estimes[indices_paquets_perdus] = -1.1

# Plot
plt.figure()
plt.plot(signal_og, label ="original voice")
plt.plot(signal_loss-2, label = "packet loss")
plt.plot(bursts, label = "packets perdus")
plt.plot(bursts_estimes, label = "packets perdus estimés")
plt.grid(alpha=0.3)
plt.legend()
plt.show()


def true_blocks_dictionnary(lst):
  """
  retourne pour une liste de True/False
  (True : il y a un paquet perdu à cet indice dans le signal sonore)
  le dictionnaire retourné a pour clés : l'indice de début du paquet perdu
  et pour valeur : la taille du paquet perdu
  """
  result = {}
  start = None  # Indice de début d'un bloc de True

  for i, val in enumerate(lst):
      if val:  # Si c'est un True
          if start is None:  # Début d'un nouveau bloc
              start = i
      else:  # Si c'est un False
          if start is not None:  # Fin d'un bloc de True
              result[start] = i - start  # Longueur du bloc
              start = None

  # Ajouter le dernier bloc s'il se termine par un True
  if start is not None:
      result[start] = len(lst) - start

  return result

# Exemple d'utilisation
lst = [True, True, False, True, True, True, False, False]
result = true_blocks_dictionnary(lst)
print(result)


def baseline_interpolation(signal_loss):
  signal_reconstruction = signal_loss.copy()

  paquets_perdus_estimes = False * np.ones(len(signal_loss))
  indices_paquets_perdus = np.where(signal_loss == 0.0)
  paquets_perdus_estimes[indices_paquets_perdus] = True

  paquets_perdus_dictionnary = true_blocks_dictionnary(paquets_perdus_estimes)
  for debut, duree in paquets_perdus_dictionnary.items():
    valeur_debut, valeur_fin = signal_loss[debut-1], signal_loss[debut+duree]
    signal_reconstruction[debut:debut+duree] = np.linspace(valeur_debut, valeur_fin, duree)

  return signal_reconstruction


signal_reconstruction = baseline_interpolation(signal_loss)


IPython.display.Audio(signal_loss, rate=samplerate)


IPython.display.Audio(signal_og, rate=samplerate)


IPython.display.Audio(signal_reconstruction, rate=samplerate)


# Estimations des paquets perdus sur le signal reconstruit
bursts_estimes = np.nan * np.ones(len(signal_loss))
indices_paquets_perdus = np.where(signal_reconstruction == 0.0)
bursts_estimes[indices_paquets_perdus] = -1.1

# Plot
plt.figure()
plt.plot(signal_og, label ="original voice")
plt.plot(signal_loss-2, label = "paquet loss")
plt.plot(bursts, label = "vrais paquets perdus")
plt.plot(bursts_estimes, label = "paquets perdus estimés sur le signal interpolé ")
plt.grid(alpha=0.3)
plt.legend()
plt.show()





def L2_squared(x):
  assert(type(x) == np.ndarray)
  return np.sum(x**2) / len(x)

def MSE(x, x_reconstructed):
  assert(type(x) == type(x_reconstructed) == np.ndarray)
  assert(x.shape == x_reconstructed.shape)
  return L2_squared(x - x_reconstructed)

def SNR(x, x_reconstructed):
  assert(type(x) == type(x_reconstructed) == np.ndarray)
  assert(x.shape == x_reconstructed.shape)
  return 10*np.log10(L2_squared(x)/L2_squared(x-x_reconstructed))

def SISNR(x, x_reconstructed):
  return None

def S_Loss1(x, x_reconstructed):
  return None

def S_Loss2(x, x_reconstructed):
  return None


mse_score_parfait = MSE(signal_og, signal_og)
mse_score_initial = MSE(signal_og, signal_loss)
mse_score_reconstruction = MSE(signal_og, signal_reconstruction)
print("MSE témoin parfait", mse_score_parfait)
print("MSE avant reconstruction :", mse_score_initial)
print("MSE après reconstruction :", mse_score_reconstruction) # Parfois encore pire après reconstruction !!


snr_score_parfait = SNR(signal_og, signal_og) #donne +inf : logique => métrique pas top pour ce genre de problèmes de paquet loss
snr_score_initial = SNR(signal_og, signal_loss)
snr_score_reconstruction = SNR(signal_og, signal_reconstruction)
print("SNR témoin parfait", snr_score_parfait)
print("SNR avant reconstruction :", snr_score_initial)
print("SNR après reconstruction :", snr_score_reconstruction)


pesq_score_parfait = pesq(samplerate, signal_og, signal_og, 'nb')  # PESQ en bande étroite (8 kHz)
pesq_score_initial = pesq(samplerate, signal_og, signal_loss, 'nb')
pesq_score_reconstruction = pesq(samplerate, signal_og, signal_reconstruction, 'nb')
print("PESQ témoin parfait", pesq_score_parfait)
print("PESQ avant reconstruction :", pesq_score_initial)
print("PESQ après reconstruction :", pesq_score_reconstruction)


stoi_score_parfait = stoi(signal_og, signal_og, samplerate)
stoi_score_initial = stoi(signal_og, signal_loss, samplerate)
stoi_score_reconstruction = stoi(signal_og, signal_reconstruction, samplerate)
print("STOI témoin parfait :", stoi_score_parfait)
print("STOI avant reconstruction :", stoi_score_initial)
print("STOI après reconstruction :", stoi_score_reconstruction)


nperseg = 256 ## A changer cf TP1

f_stft_og, t_stft_og, amplitude_stft_og = stft(signal_og, samplerate, nperseg=nperseg)
f_stft_loss, t_stft_loss, amplitude_stft_loss = stft(signal_loss, samplerate, nperseg=nperseg)
f_stft_reconstruction, t_stft_reconstruction, amplitude_stft_reconstruction = stft(signal_reconstruction, samplerate, nperseg=nperseg)

# Tracer le spectrogramme

fig, axes = plt.subplots(1, 3, figsize=(15,4))

axes[0].pcolormesh(t_stft_og, f_stft_og, np.abs(amplitude_stft_og), shading='gouraud', cmap='viridis')
axes[0].set_title("Spectrogramme (STFT) du signal original")
axes[0].set_xlabel("Temps (s)")
axes[0].set_ylabel("Fréquence (Hz)")
#axes[0].colorbar(label="Amplitude")

axes[1].pcolormesh(t_stft_loss, f_stft_loss, np.abs(amplitude_stft_loss), shading='gouraud', cmap='viridis')
axes[1].set_title("Spectrogramme (STFT) du signal avec les paquets manquants")
axes[1].set_xlabel("Temps (s)")
axes[1].set_ylabel("Fréquence (Hz)")
#axes[1].colorbar(label="Amplitude")

axes[2].pcolormesh(t_stft_reconstruction, f_stft_reconstruction, np.abs(amplitude_stft_reconstruction), shading='gouraud', cmap='viridis')
axes[2].set_title("Spectrogramme (STFT) du signal reconstruit par interpolation")
axes[2].set_xlabel("Temps (s)")
axes[2].set_ylabel("Fréquence (Hz)")
#axes[2].colorbar(label="Amplitude")

axes[2].pcolormesh(t_stft_reconstruction, f_stft_reconstruction, np.abs(amplitude_stft_og - amplitude_stft_loss), shading='gouraud', cmap='viridis')
axes[2].set_title("Spectrogramme (STFT) du signal reconstruit par interpolation")
axes[2].set_xlabel("Temps (s)")
axes[2].set_ylabel("Fréquence (Hz)")
plt.tight_layout()
plt.show()





! python3.10 -m pip install statsmodels


def ar_interpolation(signal_loss , lag = 5):
    model = AutoReg(signal_loss, lags=lag)
    model_fit = model.fit()
    pred = model_fit.predict()
    return pred
    









device = "cuda" if torch.cuda.is_available() else "cpu"
class DatasetVoice(Dataset):
    def __init__(self, chemin = ".", type_ = "train", nb_samples = 1000, transform = None):
        types = ["train", "test", "train_small"]
        if type_ not in types:
            return Exception("Please provide a correct type among those : " + str(types)) 
        dicX, dicY = charger_donnees(os.path.join(chemin, "packet_loss", type_ )), charger_donnees(os.path.join(chemin, "voice_origin", type_ ))
        
        split = len(dicX[0]["data"]) // nb_samples
        self.X = torch.zeros(len(dicX) * split, len(dicX[0]["data"]) // split)#.to(device)
        self.y = torch.zeros(len(dicY) * split, len(dicY[0]["data"]) // split)#.to(device)
        step = len(dicX[0]["data"]) // split
        for i in tqdm(range(0, len(dicX))):
            dicX[i]["data"] = dicX[i]["data"] / np.max(np.abs(dicX[i]["data"]))
            dicY[i]["data"] = dicY[i]["data"] / np.max(np.abs(dicY[i]["data"]))
            splitsX = [dicX[i]["data"][j:j+step] for j in range(0, len(dicX[i]["data"]), step)]
            splitsY = [dicY[i]["data"][j:j+step] for j in range(0, len(dicY[i]["data"]), step)]
            if split == 1:
                splits = [dicX[i]["data"]]
            for j in range(len(splitsX)):
                self.X[i * split +  j] = torch.from_numpy(splitsX[j])#.to(device)
                self.y[i * split+ j] = torch.from_numpy(splitsY[j])#.to(device)
        self.X = self.X.to(device)
        self.y = self.y.to(device)
        self.transform = transform.to(device)
    def __getitem__(self, i):
        feature, target = self.X[i], self.y[i]
        if self.transform:
            feature = self.transform(feature)
            target = self.transform(target)
        return feature, target
    def __len__(self):
        return len(self.X)


dataset_train = DatasetVoice(type_ = "train", nb_samples = 100,)
dataset_test = DatasetVoice(type_ = "test", nb_samples = 100)



prop_eval = 0.1
prop_train = 0.9
dataset_eval, dataset_train  = random_split(dataset_train, [prop_eval, prop_train])


print("Taille train : ", len(dataset_train))
print("Taille test : ", len(dataset_test))
print("Taille eval : ", len(dataset_eval))










class BaselineNet(nn.Module):
    def __init__(self, input_size = 100, output_size = 100):
        super().__init__()
        self.fc = nn.Linear(input_size, output_size).to(device)
        self.input_size = input_size
        self.output_size = output_size
    def forward(self, batch):
        output = self.fc(batch,)
        output = self.sigmoid(output,)
        return output


net = BaselineNet()


print("Nombre de paramètres : ", sum(p.numel() for p in net.parameters()))


batch_size = 32
train_loader= DataLoader(dataset_train, batch_size = batch_size, shuffle = True)
test_loader= DataLoader(dataset_test, batch_size = batch_size)
val_loader= DataLoader(dataset_eval, batch_size = batch_size)


def train(model, lr = 0.005, n_epochs = 100, print_step = 10, proportion = 0.5):
    optimizer = torch.optim.Adam(model.parameters(), lr = lr)
    loss = torch.nn.MSELoss()
    losses_eval = []
    pbar = tqdm(range(n_epochs))
    for i in pbar:
        
        model.train()
        optimizer.zero_grad()
        l = 0
        j = 0
        for batch, true_val in train_loader:
            if j * len(batch) > proportion * len(dataset_train):
                break
            output = model(batch)
            l += loss(output, true_val)
            j += 1
        l.backward()
        optimizer.step()
        model.eval()
        with torch.no_grad():
            l = 0
            for batch, true_val in val_loader:
                output = model(batch)
                l += loss(output, true_val)
            losses_eval.append(l)
            if i % print_step == 0:
                print(f"Loss eval :  {l:.2f}")
        pbar.set_description("Processing with loss : " + str(losses_eval[-1]).item())
    return losses_eval


losses = train(net, n_epochs = 200)


torch.save(net.state_dict(), "Base.model")


x = torch.zeros(800, 100)
y = torch.zeros(800, 100)
ancien = torch.zeros(800, 100)
for i in tqdm(range(0, 800)):
    ancien[i] = dataset_test[i][0]
    x[i] = (net(dataset_test[i][0].view(1, -1)))
    y[i] = dataset_test[i][1]
x = x.flatten().cpu().detach().numpy()
ancien = ancien.flatten().cpu().detach().numpy()
y = ancien.flatten().cpu().detach().numpy()


plt.xlabel("Epoch")
plt.ylabel("Loss totale")
plt.title("Evolution de la loss d'évaluation en fonction de l'époch")
plt.plot(np.arange(len(losses)), losses)
plt.legend()
plt.show()





IPython.display.Audio(ancien, rate=8000) #with packet loss


IPython.display.Audio(x, rate=8000) #with packet loss





mse_score_parfait = MSE(y, y) #donne +inf : logique => métrique pas top pour ce genre de problèmes de paquet loss
mse_score_initial = MSE(y, ancien)
mse_score_reconstruction = MSE(y, x)
print("MSE témoin parfait", mse_score_parfait)
print("MSE avant reconstruction :", mse_score_initial)
print("MSE après reconstruction :", mse_score_reconstruction)


snr_score_parfait = SNR(y, y) #donne +inf : logique => métrique pas top pour ce genre de problèmes de paquet loss
snr_score_initial = SNR(y, ancien)
snr_score_reconstruction = SNR(y, x)
print("SNR témoin parfait", snr_score_parfait)
print("SNR avant reconstruction :", snr_score_initial)
print("SNR après reconstruction :", snr_score_reconstruction)


stoi_score_parfait = stoi(y, y, samplerate)
stoi_score_initial = stoi(y, ancien, samplerate)
stoi_score_reconstruction = stoi(y, x, samplerate)
print("STOI témoin parfait :", stoi_score_parfait)
print("STOI avant reconstruction :", stoi_score_initial)
print("STOI après reconstruction :", stoi_score_reconstruction)





score_model = score(dataset_eval)
print("Score model : ", score_model)
score_base = score(dataset_eval, with_model = False)
print("Score base: ", score_base)









class Encoder(nn.Module):
    def __init__(self, input_size = 100, hidden_size = 128, num_layers = 1, bidirectional = False, dropout = 0.):
        super().__init__()
        self.rnn = nn.GRU(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers,
                          bidirectional = bidirectional, dropout = dropout, batch_first = True).to(device)
        self.bidirectional = int(bidirectional) + 1
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.input_size = input_size
    def forward(self, batch):
        #batch
        output, hiddens = self.rnn(batch, )
        h = torch.cat((hiddens[-2,:,:], hiddens[-1,:,:]), dim=-1).unsqueeze(0) # Derniere layer, deux directions
        #c = torch.cat((cells[-2,:,:], cells[-1,:,:]), dim=-1).unsqueeze(0)
        #h, c = hiddens,cells
        return h
class Decoder(nn.Module):
    def __init__(self, input_size = 100, hidden_size = 256, output_dim = 100, num_layers = 2, dropout = 0.):
        super().__init__()
        
        self.rnn = nn.GRU(input_size = input_size, hidden_size = hidden_size , num_layers = num_layers,
                           dropout = dropout, batch_first = True, bidirectional = False).to(device)
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.input_size = input_size
        self.fc = nn.Linear(hidden_size , output_dim).to(device)
        
    def forward(self, batch, h):
        
        outputs, _ = self.rnn(batch, h)
        #outputs = outputs.squeeze(1)
        preds = self.fc(outputs)
        return preds
class Seq2Seq(nn.Module):
    def __init__(self,input_size = 100, hidden_size = 128, output_dim = 100):
        super().__init__()
        self.enc = Encoder(input_size = input_size, num_layers = 2, hidden_size = hidden_size, bidirectional = True)
        self.dec = Decoder(input_size = input_size, output_dim = input_size, hidden_size = hidden_size * 2, num_layers = 1,)
    def forward(self, batch):
        batch = batch.unsqueeze(1)
        h = self.enc(batch)
        output = self.dec(batch, h)
        return output.squeeze(1)


from torch.utils.data import DataLoader
batch_size = 32
train_loader= DataLoader(dataset_train, batch_size = batch_size, shuffle = True,)
test_loader= DataLoader(dataset_test, batch_size = batch_size)
val_loader= DataLoader(dataset_eval, batch_size = batch_size)


torch.backends.cudnn.benchmark = True
model_seq = Seq2Seq()
train(model_seq, )


torch.save(model_seq.state_dict(), "Seq2seq.model")


model_seq = Seq2Seq()
model_seq.load_state_dict(torch.load("Seq2seq.model", weights_only=True))



losses_new = train(model_seq, n_epochs = 300)





def train_unet(model, lr = 0.005, n_epochs = 100, print_step = 10, type_loss = "L2", proportion = 1. ):
    optimizer = torch.optim.Adam(model.parameters(), lr = lr)
    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 20, 40, 60, 80], gamma=0.5)
    if type_loss.upper() == "L1":
        loss = torch.nn.L1Loss()
    else:
        loss = torch.nn.MSELoss()
    losses_eval = []
    losses_train = []
    pbar = tqdm(range(n_epochs))
    loss_memorized = 1000
    params_memorized = None
    index = -1
    
    try:
        for i in pbar:
    
    
            model.train()
            
            l = 0
            j = 0
            loss_train = 0
            
            for batch, phase, true_val, true_phase in train_loader:
                if j  >= proportion * len(train_loader):
                    break
                
                output = model(batch)
                #dif_target = true_val - batch
                #dif_output = true_val - output
                l = loss(output, true_val)
                j += 1
                l.backward()
                optimizer.step()
                loss_train += l.detach().item()
                optimizer.zero_grad()
            scheduler.step()
            losses_train.append(loss_train / len(dataset_train))
            model.eval()
            with torch.no_grad():
                l = 0
                for batch, _,  true_val, _ in val_loader:
                    output = model(batch)
                    l += loss(output, true_val)
    
                losses_eval.append(l.item() / len(dataset_eval))
                if i % print_step == 0:
                    print(f"Loss eval :  {losses_eval[-1]}")
                pbar.set_description("Processing with loss : " + str(losses_eval[-1]))
                if losses_eval[-1] < loss_memorized:
                    loss_memorized = losses_eval[-1]
                    params_memorized = unet.state_dict()
                    index = i
    except KeyboardInterrupt:
        print("Interruption")
    
    return losses_train, losses_eval, params_memorized, loss_memorized, index


transform = T.Spectrogram( n_fft=511, hop_length=313, power = None, )
dataset_train = DatasetVoice(nb_samples = 80000, transform = transform)



prop_eval = 0.1
dataset_eval, dataset_train = random_split(dataset_train, [prop_eval, 1 -prop_eval])


batch_size = 32
train_loader = DataLoader(dataset_train, batch_size = batch_size,)
val_loader = DataLoader(dataset_eval, batch_size = batch_size)


class UNet_interpolation_phase(nn.Module):
    def __init__(self, ):
        super().__init__()
        self.enc1 = self.down_conv(3, 16)
        self.enc2 = self.down_conv(16, 32)
        self.enc3 = self.down_conv(32, 64)
        self.enc4 = self.down_conv(64, 128)
        self.pool = nn.MaxPool2d(2, 2,)
        self.up1 = self.up(256)
        self.up2 = self.up(128)
        self.up3 = self.up(64)
        self.up4 = self.up(32)
        self.dec1 = self.up_conv(256, 128)
        self.dec2 = self.up_conv(128, 64)
        self.dec3 = self.up_conv(64, 32)
        self.dec4 = self.up_conv(32, 16)
        self.out = nn.Conv2d(16, 3, kernel_size = 1)
        self.bottom1 = nn.Conv2d(128, 256, 3, padding = 1)
        self.bottom2 = nn.Conv2d(256, 256, 3, padding = 1)
        self.tanh = nn.Tanh()
    def down_conv(self, in_channels, out_channels, kernel_size = 3):
        return nn.Sequential(
            nn.Conv2d(in_channels = in_channels, out_channels = out_channels, kernel_size = kernel_size , padding = 1, dtype= torch.float),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(in_channels = out_channels, out_channels = out_channels, kernel_size = kernel_size , padding = 1, dtype= torch.float),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            
        )
    def up(self, in_channels):
        return nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size = 2, stride = 2)
    def up_conv(self, in_channels, out_channels, kernel_size = 3):
        return nn.Sequential(
                            nn.Conv2d(in_channels = in_channels, out_channels = out_channels, kernel_size = kernel_size, padding = 1, dtype= torch.float),
                            nn.BatchNorm2d(out_channels),
                            nn.ReLU(inplace=True),
                            nn.Conv2d(in_channels = out_channels, out_channels = out_channels, kernel_size = kernel_size , padding = 1, dtype= torch.float),
                            nn.BatchNorm2d(out_channels),
                            nn.ReLU(inplace=True),
                            )
    def forward(self, batch):
        e1 = self.enc1(batch)
        e2 = self.enc2(self.pool(e1))
        e3 = self.enc3(self.pool(e2))
        e4 = self.enc4(self.pool(e3))
        e5 = self.bottom2(self.bottom1(self.pool(e4)))
        d1 = self.up1(e5)

        # batch x Cannals x height x width
        d1 = torch.cat([e4, d1], dim=1)
        d1 = self.dec1(d1)
        d2 = self.up2(d1)

        # batch x Cannals x height x width

        d2 = torch.cat([e3, d2,], dim = 1) 
        d2 = self.dec2(d2)

        d3 = self.up3(d2)

        d3 = torch.cat([e2, d3,], dim = 1) 
        d3 = self.dec3(d3)
        d4 = self.up4(d3)


        d4 = torch.cat([e1, d4,], dim = 1) 
        d4 = self.dec4(d4)
        out = self.out(d4)
        out = self.tanh(out)
        return out.squeeze(1) 


class UNet_interpolation3(nn.Module):
    def __init__(self, ):
        super().__init__()
        self.enc1 = self.down_conv(1, 16)
        self.enc2 = self.down_conv(16, 32)
        self.enc3 = self.down_conv(32, 64)
        self.enc4 = self.down_conv(64, 128)
        self.pool = nn.MaxPool2d(2, 2,)
        self.up1 = self.up(256)
        self.up2 = self.up(128)
        self.up3 = self.up(64)
        self.up4 = self.up(32)
        self.dec1 = self.up_conv(256, 128)
        self.dec2 = self.up_conv(128, 64)
        self.dec3 = self.up_conv(64, 32)
        self.dec4 = self.up_conv(32, 16)
        self.out = nn.Conv2d(16, 1, kernel_size = 1)
        self.bottom1 = nn.Conv2d(128, 256, 3, padding = 1)
        self.bottom2 = nn.Conv2d(256, 256, 3, padding = 1)
        self.sigmoid = nn.Sigmoid()
    def down_conv(self, in_channels, out_channels, kernel_size = 3):
        return nn.Sequential(
            nn.Conv2d(in_channels = in_channels, out_channels = out_channels, kernel_size = kernel_size , padding = 1, dtype= torch.float),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(in_channels = out_channels, out_channels = out_channels, kernel_size = kernel_size , padding = 1, dtype= torch.float),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            
        )
    def up(self, in_channels):
        return nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size = 2, stride = 2)
    def up_conv(self, in_channels, out_channels, kernel_size = 3):
        return nn.Sequential(
                            nn.Conv2d(in_channels = in_channels, out_channels = out_channels, kernel_size = kernel_size, padding = 1, dtype= torch.float),
                            nn.BatchNorm2d(out_channels),
                            nn.ReLU(inplace=True),
                            nn.Conv2d(in_channels = out_channels, out_channels = out_channels, kernel_size = kernel_size , padding = 1, dtype= torch.float),
                            nn.BatchNorm2d(out_channels),
                            nn.ReLU(inplace=True),
                            )
    def forward(self, batch):
        batch = batch.unsqueeze(1)
        e1 = self.enc1(batch)
        e2 = self.enc2(self.pool(e1))
        e3 = self.enc3(self.pool(e2))
        e4 = self.enc4(self.pool(e3))
        e5 = self.bottom2(self.bottom1(self.pool(e4)))
        d1 = self.up1(e5)

        # batch x Cannals x height x width

        d1 = torch.cat([e4, d1], dim=1)
        d1 = self.dec1(d1)
        d2 = self.up2(d1)

        # batch x Cannals x height x width

        d2 = torch.cat([e3, d2,], dim = 1) 
        d2 = self.dec2(d2)

        d3 = self.up3(d2)

        d3 = torch.cat([e2, d3,], dim = 1) 
        d3 = self.dec3(d3)
        d4 = self.up4(d3)


        d4 = torch.cat([e1, d4,], dim = 1) 
        d4 = self.dec4(d4)
        out = self.out(d4)
        out = self.sigmoid(out)
        return out.squeeze(1) 


class UNet_interpolation5(nn.Module):
    def __init__(self, ):
        super().__init__()
        self.enc1 = self.down_conv(1, 16)
        self.enc2 = self.down_conv(16, 32)
        self.enc3 = self.down_conv(32, 64)
        self.enc4 = self.down_conv(64, 128)
        self.pool = nn.MaxPool2d(2, 2,)
        self.up1 = self.up(256)
        self.up2 = self.up(128)
        self.up3 = self.up(64)
        self.up4 = self.up(32)
        self.dec1 = self.up_conv(256, 128)
        self.dec2 = self.up_conv(128, 64)
        self.dec3 = self.up_conv(64, 32)
        self.dec4 = self.up_conv(32, 16)
        self.out = nn.Conv2d(16, 1, kernel_size = 1)
        self.bottom1 = nn.Conv2d(128, 256, 5, padding = 2)
        self.bottom2 = nn.Conv2d(256, 256, 5, padding = 2)
        self.sigmoid = nn.Sigmoid()
    def down_conv(self, in_channels, out_channels, kernel_size = 5):
        return nn.Sequential(
            nn.Conv2d(in_channels = in_channels, out_channels = out_channels, kernel_size = kernel_size , padding = 2, dtype= torch.float),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(in_channels = out_channels, out_channels = out_channels, kernel_size = kernel_size , padding = 2, dtype= torch.float),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            
        )
    def up(self, in_channels):
        return nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size = 2, stride = 2)
    def up_conv(self, in_channels, out_channels, kernel_size = 5):
        return nn.Sequential(
                            nn.Conv2d(in_channels = in_channels, out_channels = out_channels, kernel_size = kernel_size, padding = 2, dtype= torch.float),
                            nn.BatchNorm2d(out_channels),
                            nn.ReLU(inplace=True),
                            nn.Conv2d(in_channels = out_channels, out_channels = out_channels, kernel_size = kernel_size , padding = 2, dtype= torch.float),
                            nn.BatchNorm2d(out_channels),
                            nn.ReLU(inplace=True),
                            )
    def forward(self, batch):
        batch = batch.unsqueeze(1)
        e1 = self.enc1(batch)
        e2 = self.enc2(self.pool(e1))
        e3 = self.enc3(self.pool(e2))
        e4 = self.enc4(self.pool(e3))
        e5 = self.bottom2(self.bottom1(self.pool(e4)))
        d1 = self.up1(e5)

        # batch x Cannals x height x width
        d1 = torch.cat([e4, d1], dim=1)
        d1 = self.dec1(d1)
        d2 = self.up2(d1)

        # batch x Cannals x height x width

        d2 = torch.cat([e3, d2,], dim = 1) 
        d2 = self.dec2(d2)

        d3 = self.up3(d2)

        d3 = torch.cat([e2, d3,], dim = 1) 
        d3 = self.dec3(d3)
        d4 = self.up4(d3)


        d4 = torch.cat([e1, d4,], dim = 1) 
        d4 = self.dec4(d4)
        out = self.out(d4)
        out = self.sigmoid(out)
        return out.squeeze(1) 



unet = UNet_interpolation3().to(device)



torch.backends.cudnn.benchmark = True
losses_train, losses_eval, params_mem, loss_mem, index_mem = train_unet(unet, lr = 0.02, n_epochs = 250, type_loss = "L1", proportion = 0.2)


plt.plot(losses_train, label = "Loss train")
plt.plot(losses_eval, label = "Loss eval")
plt.title("Evolution des losses de train et de validation en fonction du nombre d'epochs.")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()


torch.save(unet.state_dict(), "Unet3.model")


dataset_test = DatasetVoice(nb_samples = 80000, type_ = "test", transform = transform)


dataset = dataset_eval
index = np.random.randint(len(dataset))
print("Index choisi : ", index)
pred = unet(dataset[index][0].unsqueeze(0)).squeeze(0)
plt.title("Différence spectrogramme d'entrée et spectrogramme cible")
plt.pcolormesh(np.arange(0, 256), np.arange(0, 256), np.abs( dataset[index][0].cpu().detach().numpy() - dataset[index][2].cpu().detach().numpy() ) , shading='gouraud', cmap='viridis')
plt.show()
plt.title("Différence spectrogramme prédit et spectrogramme cible")
plt.pcolormesh(np.arange(0, 256), np.arange(0, 256), np.abs( dataset[index][2].cpu().detach().numpy() - pred.cpu().detach().numpy() ) , shading='gouraud', cmap='viridis')
plt.show()
plt.title("Différence spectrogramme prédit et spectrogramme d'entrée")
plt.pcolormesh(np.arange(0, 256), np.arange(0, 256), np.abs( dataset[index][0].cpu().detach().numpy() - pred.cpu().detach().numpy() ) , shading='gouraud', cmap='viridis')
plt.show()
phase = dataset[index][1]
amp = pred
full = torch.polar(amp.cpu().detach(), phase.cpu().detach())
signal = T.InverseSpectrogram(n_fft = 511, hop_length = 313)(full).cpu().detach().numpy()
full_original = torch.polar(dataset[index][2].cpu().detach(), dataset[index][3].cpu().detach())
full_lost = torch.polar(dataset[index][0].cpu().detach(), dataset[index][1].cpu().detach())
original_signal = T.InverseSpectrogram(n_fft = 511, hop_length = 313)(full_original).cpu().detach().numpy()
lost_signal = T.InverseSpectrogram(n_fft = 511, hop_length = 313)(full_lost).cpu().detach().numpy()




audio1 = IPython.display.Audio(signal, rate = 8000)
audio2 = IPython.display.Audio(original_signal, rate = 8000)
audio3 = IPython.display.Audio(lost_signal, rate = 8000)
pesq_predit =pesq(8000, original_signal, signal, 'nb')
pesq_lost = pesq(8000, original_signal, lost_signal, 'nb')
pesq_origin = pesq(8000, original_signal, original_signal, 'nb')
stoi_predit = stoi(original_signal, signal, 8000)
stoi_lost = stoi(original_signal, lost_signal, 8000)
stoi_origin = stoi(original_signal, original_signal, 8000)
mse_predit = ((original_signal - signal) ** 2).sum()
mse_lost = ((original_signal - lost_signal) ** 2).sum()
mse_origin = 0
print(f"Audio prédit (PESQ =  {pesq_predit} | STOI = {stoi_predit} | MSE = {mse_predit:.4f} ) ")
IPython.display.display(audio1)
print(f"Audio cible (PESQ =  {pesq_origin} | STOI = {stoi_origin} | MSE = {mse_origin:.4f} ) ")
IPython.display.display(audio2)
print(f"Audio de base (PESQ =  {pesq_lost} | STOI = {stoi_lost} | MSE = {mse_lost:.4f} ) ")
IPython.display.display(audio3)


def score_unet(dataset_train, model = None, number_examples = None):
    scores_predict = {"MSE" : [] , "SNR" : [] , "PESQ" : []  , "STOI" : [] }
    scores_old = {"MSE" : [] , "SNR" : [] , "PESQ" : []  , "STOI" : [] }
    ist = T.InverseSpectrogram(n_fft = 511, hop_length = 313).to(device)
    train_loader = DataLoader(dataset, batch_size = batch_size)
    i = 0
    for x, phase_x,  y, phase_y in tqdm(dataset):
        if i == number_examples:
            break
        i += 1
        x_old = x
        x = model(x.unsqueeze(0)).squeeze(0)
        x = torch.polar(x, phase_x)
        y = torch.polar(y, phase_y)
        x = ist(x)
        y = ist(y)
        x, y = x.cpu().detach().numpy(), y.cpu().detach().numpy()
        mse_score = ((y - x) ** 2).sum() / len(x)
        pesq_score = pesq(8000, y, x, "nb")
        stoi_score = stoi(y, x, 8000)
        scores_predict["MSE"].append(mse_score)
        scores_predict["PESQ"].append(pesq_score)
        scores_predict["STOI"].append(stoi_score)
        x_old = torch.polar(x_old, phase_x)
        x_old = ist(x_old)
        x_old, y = x_old.cpu().detach().numpy(), y
        power_noise = ((y - x) ** 2).sum() / len(x)
        power_y = (y ** 2).sum() / len(y)
        snr_score = 10 * np.log10(power_y / mse_score)
        scores_predict["SNR"].append(snr_score)
        mse_score = ((y - x_old) ** 2).sum() / len(x_old)
        pesq_score = pesq(8000, y, x_old, "nb")
        stoi_score = stoi(y, x_old, 8000)
        scores_old["MSE"].append(mse_score)
        scores_old["PESQ"].append(pesq_score)
        scores_old["STOI"].append(stoi_score)

        power_noise = ((y - x_old) ** 2).sum() / len(x_old)
        snr_score = 10 * np.log10(power_y / mse_score)
        scores_old["SNR"].append(snr_score)
        
    return scores_predict, scores_old








scores = score_unet(dataset_test, model = unet, number_examples = 100)


plt.title("Histogramme des différences de score STOI entre la prédiction et le signal de base")
plt.xlabel("Différence entre score STOI prédiction et score STOI signal d'entrée")
plt.hist(np.array(scores[0]["STOI"]) - np.array(scores[1]["STOI"]) )





plt.title("Histogramme des différences de score PESQ entre la prédiction et le signal de base")
plt.xlabel("Différence entre score PESQ prédiction et score PESQ signal d'entrée")
plt.hist(np.array(scores[0]["PESQ"]) - np.array(scores[1]["PESQ"]) )





plt.title("Histogramme des différences de score SNR entre la prédiction et le signal de base")
plt.xlabel("Différence entre score SNR prédiction et score SNR signal d'entrée")
plt.hist(np.array(scores[0]["SNR"]) - np.array(scores[1]["SNR"]) )












